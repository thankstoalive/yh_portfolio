{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#4.-신경망\" data-toc-modified-id=\"4.-신경망-1\">4. 신경망</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#4.2.1-평균-제곱-오차\" data-toc-modified-id=\"4.2.1-평균-제곱-오차-1.0.1\">4.2.1 평균 제곱 오차</a></span></li><li><span><a href=\"#4.2.2-교차-엔트로피-오차\" data-toc-modified-id=\"4.2.2-교차-엔트로피-오차-1.0.2\">4.2.2 교차 엔트로피 오차</a></span></li><li><span><a href=\"#4.2.3-미니배치-학습\" data-toc-modified-id=\"4.2.3-미니배치-학습-1.0.3\">4.2.3 미니배치 학습</a></span></li><li><span><a href=\"#4.2.4-(배치용)-교차-엔트로피-오차-구현하기\" data-toc-modified-id=\"4.2.4-(배치용)-교차-엔트로피-오차-구현하기-1.0.4\">4.2.4 (배치용) 교차 엔트로피 오차 구현하기</a></span></li></ul></li><li><span><a href=\"#4.3-수치-미분\" data-toc-modified-id=\"4.3-수치-미분-1.1\">4.3 수치 미분</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.3.1-미분\" data-toc-modified-id=\"4.3.1-미분-1.1.1\">4.3.1 미분</a></span></li><li><span><a href=\"#4.3.2-수치-미분의-예\" data-toc-modified-id=\"4.3.2-수치-미분의-예-1.1.2\">4.3.2 수치 미분의 예</a></span></li><li><span><a href=\"#4.3.3-편미분\" data-toc-modified-id=\"4.3.3-편미분-1.1.3\">4.3.3 편미분</a></span></li></ul></li><li><span><a href=\"#4.4-기울기\" data-toc-modified-id=\"4.4-기울기-1.2\">4.4 기울기</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.4.1-경사법(경사-하강법)\" data-toc-modified-id=\"4.4.1-경사법(경사-하강법)-1.2.1\">4.4.1 경사법(경사 하강법)</a></span></li><li><span><a href=\"#신경망에서의-기울기\" data-toc-modified-id=\"신경망에서의-기울기-1.2.2\">신경망에서의 기울기</a></span></li></ul></li><li><span><a href=\"#4.5-학습-알고리즘-구현하기\" data-toc-modified-id=\"4.5-학습-알고리즘-구현하기-1.3\">4.5 학습 알고리즘 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.5.1-2층-신경망-클래스-구현하기\" data-toc-modified-id=\"4.5.1-2층-신경망-클래스-구현하기-1.3.1\">4.5.1 2층 신경망 클래스 구현하기</a></span></li><li><span><a href=\"#4.5.2-미니배치-학습-구현하기\" data-toc-modified-id=\"4.5.2-미니배치-학습-구현하기-1.3.2\">4.5.2 미니배치 학습 구현하기</a></span></li><li><span><a href=\"#4.5.3-시험-데이터로-평가하기\" data-toc-modified-id=\"4.5.3-시험-데이터로-평가하기-1.3.3\">4.5.3 시험 데이터로 평가하기</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 평균 제곱 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E= {1\\over2}\\sum_{k}^{}(y_k-t_k)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E= -\\sum_{k}^{}t_klogy_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13730, 53736,  9437,  3069, 28743, 27861, 22630, 43287, 12175,\n",
       "       25550])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(60000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim==1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(t*np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.dim ==1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "        batch_size = y.shape[0]\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / 2*h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = 0.01x^2 + 0.1x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999999908982e-09"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.999999999986347e-09"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_0, x_1)=x_0^2+x_1^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.000000000003781e-08"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제1 x0=3 x1=4일 때, x0에 대한 편미분을 구하라.\n",
    "\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0+4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119e-08"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제1 x0=3 x1=4일 때, x1에 대한 편미분을 구하라.\n",
    "\n",
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1] **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x = np.array([-3.0, 4.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(function_2, init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 큰 예 : lr=10.0\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=10.0, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 예 : lr=1e-10\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38986226 -1.0129872   0.06510871]\n",
      " [-2.233992   -0.32398479 -1.54244287]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W) # 가중치 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.77667544 -0.89937863 -1.34913336]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최대값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.169392691392813"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0,0,1]) # 정답 레이블\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12150972  0.29215692 -0.41366663]\n",
      " [ 0.18226458  0.43823538 -0.62049995]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x,t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.random.randn(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.random.randn(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W : self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape) # (784,100)\n",
    "print(net.params['b1'].shape) # (100,)\n",
    "print(net.params['W2'].shape) # (100, 10)\n",
    "print(net.params['b2'].shape) # (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(100, 784) # 더미 입력 데이터\n",
    "y = net.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t) # 기울기 계산\n",
    "\n",
    "print(grads['W1'].shape) # (784, 100)\n",
    "print(grads['b1'].shape) # (100,)\n",
    "print(grads['W2'].shape) # (100, 10)\n",
    "print(grads['b2'].shape) # (10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10 # 반복 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100 # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미내배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_size]\n",
    "    t_batch = t_train[batch_size]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    # grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.10218333333333333, 0.101\n",
      "train acc, test acc | 0.78545, 0.793\n",
      "train acc, test acc | 0.8794166666666666, 0.8836\n",
      "train acc, test acc | 0.8993666666666666, 0.8987\n",
      "train acc, test acc | 0.90865, 0.9105\n",
      "train acc, test acc | 0.9149333333333334, 0.9155\n",
      "train acc, test acc | 0.9204333333333333, 0.9213\n",
      "train acc, test acc | 0.92455, 0.9252\n",
      "train acc, test acc | 0.9286833333333333, 0.9282\n",
      "train acc, test acc | 0.93125, 0.9297\n",
      "train acc, test acc | 0.93395, 0.9331\n",
      "train acc, test acc | 0.93625, 0.9355\n",
      "train acc, test acc | 0.9387666666666666, 0.9378\n",
      "train acc, test acc | 0.9408666666666666, 0.9386\n",
      "train acc, test acc | 0.9426, 0.9422\n",
      "train acc, test acc | 0.9451833333333334, 0.9425\n",
      "train acc, test acc | 0.9462333333333334, 0.9449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 10000\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
